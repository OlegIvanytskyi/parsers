{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'economy' : 'wirtschaft', 'politics' : 'politik',\n",
    "              'sport' : 'fussball', 'stars' : 'stars',\n",
    "              'hobbies' : 'hobby', 'auto' : 'autos'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with economy category\n",
      "Scraped 30 lines\n",
      "Scraped 60 lines\n",
      "Scraped 90 lines\n",
      "Scraped 120 lines\n",
      "Scraped 150 lines\n",
      "Scraped 180 lines\n",
      "Scraped 210 lines\n",
      "Scraped 240 lines\n",
      "Scraped 270 lines\n",
      "Scraped 300 lines\n",
      "Scraped 330 lines\n",
      "Scraped 360 lines\n",
      "Scraped 390 lines\n",
      "Scraped 420 lines\n",
      "Scraped 450 lines\n",
      "Scraped 480 lines\n",
      "Scraped 510 lines\n",
      "Scraped 540 lines\n",
      "Scraped 570 lines\n",
      "Scraped 600 lines\n",
      "Finished working with economy category. Scraped 600 lines\n",
      "\n",
      "600 lines of economy category have been scraped from wdr_de\n",
      "\n",
      "______________________________________________________________________________\n",
      "Working with politics category\n",
      "Scraped 30 lines\n",
      "Scraped 60 lines\n",
      "Scraped 90 lines\n",
      "Scraped 120 lines\n",
      "Scraped 150 lines\n",
      "Scraped 180 lines\n",
      "Scraped 210 lines\n",
      "Scraped 240 lines\n",
      "Scraped 270 lines\n",
      "Scraped 300 lines\n",
      "Scraped 330 lines\n",
      "Scraped 360 lines\n",
      "Scraped 390 lines\n",
      "Scraped 420 lines\n",
      "Scraped 450 lines\n",
      "Scraped 480 lines\n",
      "Scraped 510 lines\n",
      "Scraped 540 lines\n",
      "Scraped 570 lines\n",
      "Scraped 600 lines\n",
      "Finished working with politics category. Scraped 600 lines\n",
      "\n",
      "600 lines of politics category have been scraped from wdr_de\n",
      "\n",
      "______________________________________________________________________________\n",
      "Working with sport category\n",
      "Scraped 30 lines\n",
      "Scraped 60 lines\n",
      "Scraped 90 lines\n",
      "Scraped 120 lines\n",
      "Scraped 150 lines\n",
      "Scraped 180 lines\n",
      "Scraped 210 lines\n",
      "Scraped 240 lines\n",
      "Scraped 270 lines\n",
      "Scraped 300 lines\n",
      "Scraped 330 lines\n",
      "Scraped 360 lines\n",
      "Scraped 390 lines\n",
      "Scraped 420 lines\n",
      "Scraped 450 lines\n",
      "Scraped 480 lines\n",
      "Scraped 510 lines\n",
      "Scraped 540 lines\n",
      "Scraped 570 lines\n",
      "Scraped 600 lines\n",
      "Finished working with sport category. Scraped 600 lines\n",
      "\n",
      "600 lines of sport category have been scraped from wdr_de\n",
      "\n",
      "______________________________________________________________________________\n",
      "Working with stars category\n",
      "Scraped 30 lines\n",
      "Scraped 60 lines\n",
      "Scraped 90 lines\n",
      "Scraped 120 lines\n",
      "Scraped 150 lines\n",
      "Scraped 180 lines\n",
      "Scraped 210 lines\n",
      "Scraped 240 lines\n",
      "Scraped 270 lines\n",
      "Scraped 300 lines\n",
      "Scraped 330 lines\n",
      "Scraped 360 lines\n",
      "Scraped 390 lines\n",
      "Scraped 420 lines\n",
      "Scraped 450 lines\n",
      "Scraped 480 lines\n",
      "Scraped 510 lines\n",
      "Scraped 540 lines\n",
      "Scraped 570 lines\n",
      "Scraped 600 lines\n",
      "Finished working with stars category. Scraped 600 lines\n",
      "\n",
      "600 lines of stars category have been scraped from wdr_de\n",
      "\n",
      "______________________________________________________________________________\n",
      "Working with hobbies category\n",
      "Scraped 30 lines\n",
      "Scraped 60 lines\n",
      "Scraped 90 lines\n",
      "Scraped 120 lines\n",
      "Scraped 150 lines\n",
      "Scraped 180 lines\n",
      "Scraped 210 lines\n",
      "Scraped 240 lines\n",
      "Scraped 270 lines\n",
      "Scraped 300 lines\n",
      "Scraped 330 lines\n",
      "Scraped 360 lines\n",
      "Scraped 390 lines\n",
      "Scraped 420 lines\n",
      "Scraped 450 lines\n",
      "Scraped 480 lines\n",
      "Scraped 510 lines\n",
      "Scraped 540 lines\n",
      "Scraped 570 lines\n",
      "Scraped 600 lines\n",
      "Finished working with hobbies category. Scraped 600 lines\n",
      "\n",
      "600 lines of hobbies category have been scraped from wdr_de\n",
      "\n",
      "______________________________________________________________________________\n",
      "Working with auto category\n",
      "Scraped 30 lines\n",
      "Scraped 60 lines\n",
      "Scraped 90 lines\n",
      "Scraped 120 lines\n",
      "Scraped 150 lines\n",
      "Scraped 180 lines\n",
      "Scraped 210 lines\n",
      "Scraped 240 lines\n",
      "Scraped 270 lines\n",
      "Scraped 300 lines\n",
      "Scraped 330 lines\n",
      "Scraped 360 lines\n",
      "Scraped 390 lines\n",
      "Scraped 420 lines\n",
      "Scraped 450 lines\n",
      "Scraped 480 lines\n",
      "Scraped 510 lines\n",
      "Scraped 540 lines\n",
      "Scraped 570 lines\n",
      "Scraped 600 lines\n",
      "Finished working with auto category. Scraped 600 lines\n",
      "\n",
      "600 lines of auto category have been scraped from wdr_de\n",
      "\n",
      "______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for category, path in categories.items():\n",
    "    print(f'Working with {category} category')\n",
    "\n",
    "    lines = []\n",
    "    page_num = 1\n",
    "\n",
    "    while True:\n",
    "        url = f'https://www1.wdr.de/suche/index.jsp?pageNumber={page_num}&q={path}#customForm-cptblock-wdrsucheinclude100'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        \n",
    "        div = soup.find_all('div', class_='boxCon')[-1]\n",
    "        if div is None:\n",
    "            break\n",
    "\n",
    "        divs = div.find_all('div', class_='box')\n",
    "        if divs == []:\n",
    "            break\n",
    "\n",
    "        for div in divs:\n",
    "            teaser_headline = div.find('div', class_='teaser').find('h3', class_='headline')\n",
    "            teaser = div.find('div', class_='teaser').find('p', class_='teasertext')\n",
    "            \n",
    "            if None in (teaser_headline, teaser):\n",
    "                continue\n",
    "            \n",
    "            # going to the page of the article to get keywords\n",
    "            href = teaser_headline.find('a')['href']\n",
    "            try:\n",
    "                article = requests.get(href)\n",
    "                article_soup = BeautifulSoup(article.content, 'html.parser')\n",
    "                keywords = ' '.join(article_soup.find('meta', attrs={'name':'Keywords'})['content'].split(','))\n",
    "            except TypeError:\n",
    "                keywords = ''\n",
    "                \n",
    "            teaser_headline = teaser_headline.text.strip()\n",
    "            teaser = teaser.text.strip()\n",
    "\n",
    "            lines.append(teaser_headline)\n",
    "            lines.append(teaser)\n",
    "            lines.append(keywords)\n",
    "            \n",
    "        print(f'Scraped {len(lines)} lines')\n",
    "\n",
    "        page_num += 1\n",
    "        if page_num > 20:  # 20 - number of pages\n",
    "            break\n",
    "            \n",
    "    print(f'Finished working with {category} category. Scraped {len(lines)} lines\\n')\n",
    "    write_to_file(lines, category, 'wdr_de')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
